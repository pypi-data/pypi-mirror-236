{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T16:06:14.135806Z",
     "start_time": "2021-11-26T16:06:13.243942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use scipy logsumexp().\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "import bayesian_changepoint_detection.generate_data as gd\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from os.path import basename,join,dirname\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal, norm\n",
    "from tqdm import tqdm\n",
    "from bayesian_changepoint_detection.priors import const_prior\n",
    "from bayesian_changepoint_detection.offline_likelihoods import IndepentFeaturesLikelihood\n",
    "import bayesian_changepoint_detection.online_likelihoods as online_ll\n",
    "from bayesian_changepoint_detection.bayesian_models import offline_changepoint_detection \n",
    "from bayesian_changepoint_detection.bayesian_models import online_changepoint_detection\n",
    "from functools import partial\n",
    "from bayesian_changepoint_detection.hazard_functions import constant_hazard\n",
    "from bayesian_changepoint_detection.priors import const_prior\n",
    "from functools import partial\n",
    "\n",
    "from bayesian_changepoint_detection.bayesian_models import offline_changepoint_detection\n",
    "import bayesian_changepoint_detection.offline_likelihoods as offline_ll\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "\n",
    "def drop_constant(data):\n",
    "    for c in data.columns:\n",
    "        if np.min(data[c]) == np.max(data[c]):\n",
    "            data = data.drop(c, axis=1)\n",
    "    return data\n",
    "\n",
    "def read_data(data_path = None):\n",
    "    if data_path is None:\n",
    "        data_path = \"/home/luan/ws/cfm/data/fse-ss/carts_cpu/2/simple_data.csv\"\n",
    "    data = pd.read_csv(data_path)\n",
    "    selected_cols = []\n",
    "    for c in data.columns:\n",
    "        if 'queue-master' in c or 'rabbitmq_' in c: continue \n",
    "        if \"latency-50\" in c or \"_error\" in c:\n",
    "            selected_cols.append(c)\n",
    "\n",
    "    data = data[selected_cols]\n",
    "    data = drop_constant(data)\n",
    "    data = data.fillna(method=\"ffill\")\n",
    "    data = data.fillna(0)\n",
    "\n",
    "    for c in data.columns:\n",
    "        data[c] = (data[c] - np.min(data[c])) / (np.max(data[c]) - np.min(data[c]))\n",
    "    data = data.fillna(method=\"ffill\")\n",
    "    data = data.fillna(0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bocpd(data : pd.DataFrame):\n",
    "    anomalies = []\n",
    "    for col in data.columns:\n",
    "        values = data[col]\n",
    "\n",
    "        prior_function = partial(const_prior, p=1/(len(values) + 1))\n",
    "        Q, P, Pcp = offline_changepoint_detection(values, prior_function ,offline_ll.StudentT())\n",
    "        anomalies.extend(np.where(np.exp(Pcp).sum(0) > 0.6)[0].tolist())\n",
    "    # merge continuous timepoint\n",
    "    anomalies = sorted(anomalies)\n",
    "    merged_anomalies = [anomalies[i] for i in range(len(anomalies)) if i == 0 or anomalies[i] - anomalies[i-1] > 1]\n",
    "    return merged_anomalies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [1:46:21<00:00, 638.19s/it]\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "import random \n",
    "data_paths = glob.glob(\"/home/luan/ws/cfm/data/fse-ss/**/simple_data.csv\", recursive=True)\n",
    "random.shuffle(data_paths)\n",
    "for data_path in tqdm(data_paths[:10]):\n",
    "    cnt +=1\n",
    "    data = read_data(data_path)\n",
    "    output = bocpd(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [2:22:32<00:00, 855.24s/it] \n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "import random \n",
    "data_paths = glob.glob(\"/home/luan/ws/cfm/data/fse-ob/**/simple_data.csv\", recursive=True)\n",
    "random.shuffle(data_paths)\n",
    "for data_path in tqdm(data_paths[:10]):\n",
    "    cnt +=1\n",
    "    data = read_data(data_path)\n",
    "    output = bocpd(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "annorxiver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
