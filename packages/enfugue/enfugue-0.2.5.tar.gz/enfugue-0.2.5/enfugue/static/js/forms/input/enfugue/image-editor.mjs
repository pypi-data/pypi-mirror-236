import{SelectInputView}from"../enumerable.mjs";class ImageColorSpaceInputView extends SelectInputView{static defaultOptions={invert:"White on Black"};static defaultValue="invert";static placeholder="Black on White";static allowEmpty=!0}class ControlNetInputView extends SelectInputView{static defaultValue="canny";static defaultOptions={canny:"Canny Edge Detection",hed:"Holistically-nested Edge Detection (HED)",pidi:"Soft Edge Detection (PIDI)",mlsd:"Mobile Line Segment Detection (MLSD)",line:"Line Art",anime:"Anime Line Art",scribble:"Scribble",depth:"Depth Detection (MiDaS)",normal:"Normal Detection (Estimate)",pose:"Pose Detection (DWPose/OpenPose)",qr:"QR Code"};static tooltip="The ControlNet to use depends on your input image. Unless otherwise specified, your input image will be processed through the appropriate algorithm for this ControlNet prior to diffusion.<br /><strong>Canny Edge</strong>: This network is trained on images and the edges of that image after having run through Canny Edge detection.<br /><strong>HED</strong>: Short for Holistically-Nested Edge Detection, this edge-detection algorithm is best used when the input image is too blurry or too noisy for Canny Edge detection.<br /><strong>Soft Edge Detection</strong>: Using a Pixel Difference Network, this edge-detection algorithm can be used in a wide array of applications.<br /><strong>MLSD</strong>: Short for Mobile Line Segment Detection, this edge-detection algorithm searches only for straight lines, and is best used for geometric or architectural images.<br /><strong>Line Art</strong>: This model is capable of rendering images to line art drawings. The controlnet was trained on the model output, this provides a great way to provide your own hand-drawn pieces as well as another means of edge detection.<br /><strong>Anime Line Art</strong>: This is similar to the above, but focusing specifically on anime style.<br /><strong>Scribble</strong>: This ControlNet was trained on a variant of the HED edge-detection algorithm, and is good for hand-drawn scribbles with thick, variable lines.<br /><strong>Depth</strong>: This uses Intel's MiDaS model to estimate monocular depth from a single image. This uses a greyscale image showing the distance from the camera to any given object.<br /><strong>Normal</strong>: Normal maps are similar to depth maps, but instead of using a greyscale depth, three sets of distance data is encoded into red, green and blue channels.<br /><strong>DWPose/OpenPose</strong>: OpenPose is an AI model from the Carnegie Mellon University's Perceptual Computing Lab detects human limb, face and digit poses from an image, and DWPose is a faster and more accurate model built on top of OpenPose. Using this data, you can generate different people in the same pose.<br /><strong>QR Code</strong> is a specialized control network designed to generate images from QR codes that are scannable QR codes themselves."}class ImageFitInputView extends SelectInputView{static defaultValue="actual";static defaultOptions={actual:"Actual Size",stretch:"Stretch",contain:"Contain",cover:"Cover"};static tooltip="Fit this image within it's container.<br /><strong>Actual</strong>: Do not manipulate the dimensions of the image, anchor it as specified in the frame.<br /><strong>Stretch</strong>: Force the image to fit within the frame, regardles sof original dimensions. When using this mode, anchor has no effect.<br /><strong>Contain</strong>: Scale the image so that it's largest dimension is contained within the frames bounds, adding negative space to fill the rest of the frame.<br /><strong>Cover</strong>: Scale the image so that it's smallest dimension is contained within the frame bounds, cropping the rest of the image as needed."}class ImageAnchorInputView extends SelectInputView{static defaultValue="top-left";static defaultOptions={"top-left":"Top Left","top-center":"Top Center","top-right":"Top Right","center-left":"Center Left","center-center":"Center Center","center-right":"Center Right","bottom-left":"Bottom Left","bottom-center":"Bottom Center","bottom-right":"Bottom Right"};static tooltip="When the size of the frame and the size of the image do not match, this will control where the image is placed. View the 'fit' field for more options to fit images in the frame."}class FilterSelectInputView extends SelectInputView{static placeholder="None";static allowEmpty=!0;static defaultOptions={invert:"Invert",pixelize:"Pixelize",box:"Box Blur",gaussian:"Gaussian Blur",sharpen:"Sharpen"}}export{ControlNetInputView,ImageAnchorInputView,ImageFitInputView,ImageColorSpaceInputView,FilterSelectInputView};
