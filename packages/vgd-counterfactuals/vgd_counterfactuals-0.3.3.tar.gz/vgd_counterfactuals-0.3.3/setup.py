# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['experiments',
 'vgd_counterfactuals',
 'vgd_counterfactuals.examples',
 'vgd_counterfactuals.experiments',
 'vgd_counterfactuals.generate']

package_data = \
{'': ['*'],
 'experiments': ['results/*'],
 'vgd_counterfactuals': ['templates/*'],
 'vgd_counterfactuals.experiments': ['results/*']}

install_requires = \
['click>=7.1.2',
 'dimorphite-dl>=1.3.2',
 'jinja2>=3.0.3',
 'matplotlib>=3.5.3',
 'numpy>=1.23.2',
 'poetry-bumpversion>=0.3.0',
 'pycomex>=0.9.2',
 'python-decouple>=3.6',
 'rdkit>=2022.9.5',
 'visual_graph_datasets>=0.13.4']

entry_points = \
{'console_scripts': ['vgd_counterfactuals = vgd_counterfactuals.cli:cli']}

setup_kwargs = {
    'name': 'vgd-counterfactuals',
    'version': '0.3.3',
    'description': 'Counterfactual explanations for GNNs based on the visual graph dataset format',
    'long_description': '|made-with-python| |python-version| |version|\n\n.. |made-with-python| image:: https://img.shields.io/badge/Made%20with-Python-1f425f.svg\n   :target: https://www.python.org/\n   :alt: made with python\n\n.. |python-version| image:: https://img.shields.io/badge/Python-3.8.0-green.svg\n   :target: https://www.python.org/\n   :alt: python 3.8\n\n.. |version| image:: https://img.shields.io/badge/version-0.3.2-orange.svg\n   :target: https://www.python.org/\n   :alt: version\n\n.. image:: banner.png\n   :alt: banner image\n\n===================\nVGD Counterfactuals\n===================\n\nLibrary for the generation and more importantly the easy visualization of **Counterfactuals** for\n**Graph Neural Networks (GNNs)** based on the\n`VisualGraphDatasets <https://github.com/awa59kst120df/visual_graph_datasets>`_\ndataset format.\n\nWhat are Counterfactuals?\n=========================\n\nCounterfactuals are a method of explaining the predictions of complex machine learning models. For a certain\nprediction of a model, a counterfactual is an input element that is as similar as possible to the original\ninput, but causes the largest possible deviation w.r.t. to the original model output prediction.\nThey are sort of "counter examples" for the behavior of a model and can help to understand the decision\nboundary of the model.\n\nThe subject of this package are graph counterfactuals. They are generated by maximizing a customizable\ndistance function in regards to the prediction output over all immediate neighbors of the original graph\nw.r.t. to the allowed, domain-specific graph edit operations.\n\nInstallation\n============\n\n.. code-block:: console\n\n    git clone https://github.com/the16thpythonist/vgd_counterfactuals\n\nThen in the main folder run a ``pip install``:\n\n.. code-block:: console\n\n    cd vgd_counterfactuals\n    python3 -m pip install .\n\nAfterwards, you can check the install by invoking the CLI:\n\n.. code-block:: console\n\n    python3 -m vgd_counterfactuals.cli --version\n    python3 -m vgd_counterfactuals.cli --help\n\n\nQuickstart\n==========\n\nThe generation of counterfactual graphs is implemented via the ``CounterfactualGenerator`` class.\nThe instantiation of one such object requires the following 4 main components:\n\n- ``processing``: A visual_graph_dataset "Processing" object. These implement the necessary functionality\n  to convert a domain-specific graph representation into the full graph structure for the machine learning\n  models. These are shipped with each specific visual graph dataset.\n- ``model``: The model to be explained. This model has to implement the visual_graph_dataset "PredictGraph"\n  interface to ensure that the model can be directly queried with the vgd GraphDict representation of\n  graph elements.\n- ``neighborhood_func``: A function which receives the domain-specific representation of a graph as an\n  input and is supposed to return a list of all the domain-specific representations of the\n  *immediate neighbors* of that graph. The implementation for this is highly specific to each application\n  domain.\n- ``distance_func``: A function which receives to arguments: The prediction of the original element and the\n  prediction of a neighbor and should return a single numeric value for the distance between the two\n  predictions. The generator will maximize this distance measure.\n\nAfter the generator object was instantiated, it can be used to create counterfactuals for any number of\ninput elements using the ``generate`` method.\n\nThe following example shows a quickstart mock example of how all of this can be used. For more information\nhave a look at the example modules provided in the ``examples`` folder of the repository.\n\n.. code-block:: python\n\n    import tempfile\n\n    from visual_graph_datasets.processing.molecules import MoleculeProcessing\n\n    from vgd_counterfactuals.base import CounterfactualGenerator\n    from vgd_counterfactuals.testing import MockModel\n    from vgd_counterfactuals.generate.molecules import get_neighborhood\n\n    processing = MoleculeProcessing()\n    model = MockModel()\n\n    generator = CounterfactualGenerator(\n        processing=processing,\n        model=model,\n        neighborhood_func=get_neighborhood,\n        distance_func=lambda orig, mod: abs(orig - mod),\n    )\n\n    with tempfile.TemporaryDirectory() as path:\n        # The "generate" function will create all the possible neighbors of the\n        # given "original" element, then query the model for to predict the\n        # output for each of them, and sort them by their distance to the original.\n        # The top k elements will be turned into a temporary visual graph dataset\n        # within the given folder "path". That means in that folder two files will\n        # be created per element: A metadata JSON file and a visualization PNG file.\n        # Returns the dictionary for the loaded visual graph dataset.\n        index_data_map = generator.generate(\n            original=\'CCCCCC\',\n            # Path to the folder into which to save the vgd element files\n            path=path,\n            # The number of counterfactuals to be returned.\n            # Elements will be sorted by their distance.\n            k_results=10,\n        )\n\n        # The keys of the resulting dict are the integer indices and the values\n        # are dicts themselves which describe the corresponding vgd elements.\n        # These dicts contain for example the absolute path to the PNG file,\n        # the full graph representation and additional metadata.\n        print(f\'generated {len(index_data_map)} counterfactuals:\')\n        for index, data in index_data_map.items():\n            print(f\' * {data["metadata"]["name"]} \'\n                  f\' - distance: {data["metadata"]["distance"]:.2f}\')\n\n\n\nCredits\n=======\n\n* `PyComex <https://github.com/the16thpythonist/pycomex.git>`_\n  is a micro framework which simplifies the setup, processing and management of computational\n  experiments. It is also used to auto-generate the command line interface that can be used to interact\n  with these experiments.\n* `VisualGraphDatasets <https://github.com/awa59kst120df/visual_graph_datasets>`_\n  is a library which deals with the VGD dataset format. In this format, graph datasets\n  for machine learning are represented by a folder, where each graph is represented by *two* files: A\n  metadata JSON file that contains the full graph representation and additional metadata and a PNG\n  visualization of the graph. The library aims to provide a framework for explainable graph machine learning\n  which is easier to use and produces more reproducable results.\n',
    'author': 'Jonas Teufel',
    'author_email': 'jonseb1998@gmail.com',
    'maintainer': 'Jonas Teufel',
    'maintainer_email': 'jonseb1998@gmail.com',
    'url': None,
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'entry_points': entry_points,
    'python_requires': '>=3.9,<=3.12',
}


setup(**setup_kwargs)
