Metadata-Version: 2.1
Name: wow-ai-vision
Version: 0.0.4
Summary: A set of easy-to-use utils that will come in handy in any Computer Vision project
Home-page: https://github.com/wow-ai/wow_ai_vision
License: MIT
Keywords: machine-learning,deep-learning,vision,ML,DL,AI,YOLOv5,YOLOv8,SAM
Author: huonghx
Author-email: huonghx@wow-ai.com
Maintainer: huonghx
Maintainer-email: huonghx@wow-ai.com
Requires-Python: >=3.8,<3.12.0
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Education
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: MacOS
Classifier: Operating System :: Microsoft :: Windows
Classifier: Operating System :: POSIX :: Linux
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3 :: Only
Classifier: Topic :: Scientific/Engineering
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Scientific/Engineering :: Image Recognition
Classifier: Topic :: Software Development
Classifier: Typing :: Typed
Provides-Extra: desktop
Requires-Dist: matplotlib (>=3.7.1,<4.0.0)
Requires-Dist: numpy (>=1.20.0,<2.0.0)
Requires-Dist: opencv-python (>=4.8.0.74,<5.0.0.0) ; extra == "desktop"
Requires-Dist: opencv-python-headless (>=4.8.0.74,<5.0.0.0)
Requires-Dist: pillow (>=9.4,<11.0)
Requires-Dist: pyyaml (>=6.0,<7.0)
Requires-Dist: scipy (>=1.9.0,<2.0.0)
Project-URL: Documentation, https://github.com/wow-ai/wow_ai_vision/blob/main/README.md
Project-URL: Repository, https://github.com/wow-ai/wow_ai_vision
Description-Content-Type: text/markdown


## ğŸ‘‹ hello

**We write your reusable computer vision tools.** Whether you need to load your dataset from your hard drive, draw detections on an image or video, or count how many detections are in a zone. You can count on us! ğŸ¤

## ğŸ’» install

Pip install the wow-ai-vision package in a
[**3.11>=Python>=3.8**](https://www.python.org/) environment.

```bash
pip install wow-ai-vision[desktop]
```

Read more about desktop, headless, and local installation in our [guide](https://).

## ğŸ”¥ quickstart

### [detections processing](https://)

```python
>>> import wow-ai-vision as sv
>>> from ultralytics import YOLO

>>> model = YOLO('yolov8s.pt')
>>> result = model(IMAGE)[0]
>>> detections = sv.Detections.from_ultralytics(result)

>>> len(detections)
5
```

<details close>
<summary>ğŸ‘‰ more detections utils</summary>

- Easily switch inference pipeline between supported object detection/instance segmentation models

    ```python
    >>> import wow-ai-vision as sv
    >>> from segment_anything import sam_model_registry, SamAutomaticMaskGenerator

    >>> sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)
    >>> mask_generator = SamAutomaticMaskGenerator(sam)
    >>> sam_result = mask_generator.generate(IMAGE)
    >>> detections = sv.Detections.from_sam(sam_result=sam_result)
    ```

- [Advanced filtering](https://)

    ```python
    >>> detections = detections[detections.class_id == 0]
    >>> detections = detections[detections.confidence > 0.5]
    >>> detections = detections[detections.area > 1000]
    ```

- Image annotation

    ```python
    >>> import wow-ai-vision as sv

    >>> box_annotator = sv.BoxAnnotator()
    >>> annotated_frame = box_annotator.annotate(
    ...     scene=IMAGE,
    ...     detections=detections
    ... )
    ```

</details>

### [datasets processing](https://)

```python
>>> import wow-ai-vision as sv

>>> dataset = sv.DetectionDataset.from_yolo(
...     images_directory_path='...',
...     annotations_directory_path='...',
...     data_yaml_path='...'
... )

>>> dataset.classes
['dog', 'person']

>>> len(dataset)
1000
```

<details close>
<summary>ğŸ‘‰ more dataset utils</summary>

- Load object detection/instance segmentation datasets in one of the supported formats

    ```python
    >>> dataset = sv.DetectionDataset.from_yolo(
    ...     images_directory_path='...',
    ...     annotations_directory_path='...',
    ...     data_yaml_path='...'
    ... )

    >>> dataset = sv.DetectionDataset.from_pascal_voc(
    ...     images_directory_path='...',
    ...     annotations_directory_path='...'
    ... )

    >>> dataset = sv.DetectionDataset.from_coco(
    ...     images_directory_path='...',
    ...     annotations_path='...'
    ... )
    ```

- Loop over dataset entries

    ```python
    >>> for name, image, labels in dataset:
    ...     print(labels.xyxy)

    array([[404.      , 719.      , 538.      , 884.5     ],
           [155.      , 497.      , 404.      , 833.5     ],
           [ 20.154999, 347.825   , 416.125   , 915.895   ]], dtype=float32)
    ```

- Split dataset for training, testing, and validation

    ```python
    >>> train_dataset, test_dataset = dataset.split(split_ratio=0.7)
    >>> test_dataset, valid_dataset = test_dataset.split(split_ratio=0.5)

    >>> len(train_dataset), len(test_dataset), len(valid_dataset)
    (700, 150, 150)
    ```

- Merge multiple datasets

    ```python
    >>> ds_1 = sv.DetectionDataset(...)
    >>> len(ds_1)
    100
    >>> ds_1.classes
    ['dog', 'person']

    >>> ds_2 = sv.DetectionDataset(...)
    >>> len(ds_2)
    200
    >>> ds_2.classes
    ['cat']

    >>> ds_merged = sv.DetectionDataset.merge([ds_1, ds_2])
    >>> len(ds_merged)
    300
    >>> ds_merged.classes
    ['cat', 'dog', 'person']
    ```

- Save object detection/instance segmentation datasets in one of the supported formats

    ```python
    >>> dataset.as_yolo(
    ...     images_directory_path='...',
    ...     annotations_directory_path='...',
    ...     data_yaml_path='...'
    ... )

    >>> dataset.as_pascal_voc(
    ...     images_directory_path='...',
    ...     annotations_directory_path='...'
    ... )

    >>> dataset.as_coco(
    ...     images_directory_path='...',
    ...     annotations_path='...'
    ... )
    ```

- Convert labels between supported formats

    ```python
    >>> sv.DetectionDataset.from_yolo(
    ...     images_directory_path='...',
    ...     annotations_directory_path='...',
    ...     data_yaml_path='...'
    ... ).as_pascal_voc(
    ...     images_directory_path='...',
    ...     annotations_directory_path='...'
    ... )
    ```

- Load classification datasets in one of the supported formats

    ```python
    >>> cs = sv.ClassificationDataset.from_folder_structure(
    ...     root_directory_path='...'
    ... )
    ```

- Save classification datasets in one of the supported formats

    ```python
    >>> cs.as_folder_structure(
    ...     root_directory_path='...'
    ... )
    ```

</details>

### [model evaluation](https://)

```python
>>> import wow-ai-vision as sv

>>> dataset = sv.DetectionDataset.from_yolo(...)

>>> def callback(image: np.ndarray) -> sv.Detections:
...     ...

>>> confusion_matrix = sv.ConfusionMatrix.benchmark(
...     dataset = dataset,
...     callback = callback
... )

>>> confusion_matrix.matrix
array([
    [0., 0., 0., 0.],
    [0., 1., 0., 1.],
    [0., 1., 1., 0.],
    [1., 1., 0., 0.]
])
```

<details close>
<summary>ğŸ‘‰ more metrics</summary>

- Mean average precision (mAP) for object detection tasks.

    ```python
    >>> import wow-ai-vision as sv

    >>> dataset = sv.DetectionDataset.from_yolo(...)

    >>> def callback(image: np.ndarray) -> sv.Detections:
    ...     ...

    >>> mean_average_precision = sv.MeanAveragePrecision.benchmark(
    ...     dataset = dataset,
    ...     callback = callback
    ... )

    >>> mean_average_precision.map50_95
    0.433
    ```

</details>

## ğŸ¬ tutorials


## ğŸ’œ built with wow-ai-vision


## ğŸ“š documentation



## ğŸ† contribution

